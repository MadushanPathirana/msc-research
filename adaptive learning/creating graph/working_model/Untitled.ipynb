{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d493dc6-4cdb-4cfb-82ff-465e21dc3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Creating a function f(X) with a slope of -5\n",
    "X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "func = -5 * X\n",
    "# Adding Gaussian noise to the function f(X) and saving it in Y\n",
    "Y = func + 0.4 * torch.randn(X.size())\n",
    "\n",
    "w = torch.tensor(-10.0, requires_grad=True)\n",
    "b = torch.tensor(-20.0, requires_grad=True)\n",
    "\n",
    "# defining the function for forward pass for prediction\n",
    "def forward(x):\n",
    "    return w * x + b\n",
    "\n",
    "# evaluating data points with Mean Square Error (MSE)\n",
    "def criterion(y_pred, y):\n",
    "    return torch.mean((y_pred - y) ** 2)\n",
    "\n",
    "# Creating our dataset class\n",
    "class Build_Data(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "        self.y = -5 * X\n",
    "        self.len = self.x.shape[0]\n",
    "    # Getting the data\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    # Getting length of the data\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Creating DataLoader object\n",
    "dataset = Build_Data()\n",
    "train_loader_10 = DataLoader(dataset=dataset, batch_size=10)\n",
    "\n",
    "step_size = 0.1\n",
    "loss_MBGD_10 = []\n",
    "n_iter = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f2b263-db34-425b-91ee-f7d20ef64703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(n_iter):\n",
    "    # calculating loss as in the beginning of an epoch and storing it\n",
    "    y_pred = forward(X)\n",
    "    loss_MBGD_10.append(criterion(y_pred, Y).tolist())\n",
    "    for x, y in train_loader_10:\n",
    "        # making a prediction in forward pass\n",
    "        y_hat = forward(x)\n",
    "        # calculating the loss between original and predicted data points\n",
    "        loss = criterion(y_hat, y)\n",
    "        # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "        loss.backward()\n",
    "        # updateing the parameters after each iteration\n",
    "        w.data = w.data - step_size * w.grad.data\n",
    "        b.data = b.data - step_size * b.grad.data\n",
    "        # zeroing gradients after each iteration\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24fa3f-2430-4087-9629-2caac4928073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46aa279-f714-4749-8c8b-c2a1cfc3db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_20 = DataLoader(dataset=dataset, batch_size=20)\n",
    "\n",
    "# Reset w and b\n",
    "w = torch.tensor(-10.0, requires_grad=True)\n",
    "b = torch.tensor(-20.0, requires_grad=True)\n",
    "\n",
    "loss_MBGD_20 = []\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # calculating loss as in the beginning of an epoch and storing it\n",
    "    y_pred = forward(X)\n",
    "    loss_MBGD_20.append(criterion(y_pred, Y).tolist())\n",
    "    for x, y in train_loader_20:\n",
    "        # making a prediction in forward pass\n",
    "        y_hat = forward(x)\n",
    "        # calculating the loss between original and predicted data points\n",
    "        loss = criterion(y_hat, y)\n",
    "        # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "        loss.backward()\n",
    "        # updating the parameters after each iteration\n",
    "        w.data = w.data - step_size * w.grad.data\n",
    "        b.data = b.data - step_size * b.grad.data\n",
    "        # zeroing gradients after each iteration\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fbed451-2494-497d-9475-e8b92713c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6633396744728088\n",
      "Epoch 2/20, Loss: 0.6632982492446899\n",
      "Epoch 3/20, Loss: 0.6632441878318787\n",
      "Epoch 4/20, Loss: 0.6631776690483093\n",
      "Epoch 5/20, Loss: 0.6630991101264954\n",
      "Epoch 6/20, Loss: 0.6630086302757263\n",
      "Epoch 7/20, Loss: 0.6629065275192261\n",
      "Epoch 8/20, Loss: 0.6627931594848633\n",
      "Epoch 9/20, Loss: 0.6626687049865723\n",
      "Epoch 10/20, Loss: 0.6625335216522217\n",
      "Epoch 11/20, Loss: 0.6623878479003906\n",
      "Epoch 12/20, Loss: 0.662231981754303\n",
      "Epoch 13/20, Loss: 0.6620661616325378\n",
      "Epoch 14/20, Loss: 0.6618906259536743\n",
      "Epoch 15/20, Loss: 0.6617057919502258\n",
      "Epoch 16/20, Loss: 0.6615117788314819\n",
      "Epoch 17/20, Loss: 0.661309003829956\n",
      "Epoch 18/20, Loss: 0.6610974669456482\n",
      "Epoch 19/20, Loss: 0.6608775854110718\n",
      "Epoch 20/20, Loss: 0.6606496572494507\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Custom dataset (replace this with your own data loading mechanism)\n",
    "# Assume X_train is a tensor of shape (num_samples, num_features)\n",
    "# Assume y_train is a tensor of shape (num_samples, 1)\n",
    "X_train = torch.rand((100, 10))\n",
    "y_train = torch.randint(0, 2, (100, 1), dtype=torch.float)\n",
    "\n",
    "# Training loop\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_start in range(0, len(X_train), batch_size):\n",
    "        # Create a mini-batch\n",
    "        batch_end = min(batch_start + batch_size, len(X_train))\n",
    "        inputs = X_train[batch_start:batch_end]\n",
    "        targets = y_train[batch_start:batch_end]\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss at the end of each epoch\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16676aac-f029-45aa-b39a-ab7c98baa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "942d35c7-e75d-48dc-b6af-a0b34df28f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([X_train,X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9a886f4-668e-4037-8e65-8acc3546140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2361, 0.2371, 0.7419, 0.4869, 0.0195, 0.2144, 0.2686, 0.0361, 0.5640,\n",
       "         0.6782],\n",
       "        [0.4083, 0.3010, 0.4970, 0.1029, 0.1955, 0.4886, 0.9442, 0.3462, 0.7478,\n",
       "         0.3032],\n",
       "        [0.3669, 0.0240, 0.9142, 0.9869, 0.4895, 0.8177, 0.9090, 0.7484, 0.7575,\n",
       "         0.0240],\n",
       "        [0.0302, 0.1162, 0.6564, 0.0675, 0.1183, 0.2576, 0.0392, 0.5007, 0.5721,\n",
       "         0.2074]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06988c72-d269-43c1-add9-2a2a74e3404f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584829d-31e6-4855-a20e-768578be750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=GNN_Classifier()\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=5e-10)\n",
    "criterion=torch.nn.BCELoss()\n",
    "best_score=0\n",
    "\n",
    "test_lost_list = []\n",
    "train_lost_list = []\n",
    "print_size=1\n",
    "model.train() \n",
    "for epoch_num in range(10):\n",
    "    epoch_accuracy = []\n",
    "    epoch_pred_prob = []\n",
    "    epoch_loss= 0\n",
    "    \n",
    "    for user_count,question_sequence in enumerate(users_question_sequence_train_lists):\n",
    "        question_sequence_len=question_sequence.shape[1]\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        out=model(data.x_dict, data.edge_index_dict,lookback,question_sequence) \n",
    "        target_answers=torch.tensor([question_sequence[2][lookback:]],dtype=torch.float).view(-1,1).float()\n",
    "        loss=F.binary_cross_entropy(out,target_answers)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accuracy =(out.view(1,-1)[0].detach().round() ==  target_answers.view(1,-1)[0])*1\n",
    "        \n",
    "        train_loss = loss.item()\n",
    "        epoch_loss =  epoch_loss + train_loss\n",
    "        epoch_accuracy.extend(accuracy)\n",
    "        epoch_pred_prob.extend(out.view(1,-1)[0].detach().tolist())\n",
    "        \n",
    "        test_loss,test_peformance=test(model)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if (epoch_num+1)%print_size==0:\n",
    "        epoch_loss =epoch_loss\n",
    "        epoch_mean_acc = np.mean(epoch_accuracy)\n",
    "        \n",
    "        roc_auc=roc_auc_score(target_answer_list,epoch_pred_prob)\n",
    "        \n",
    "        print(f'Train epoch_num {epoch_num+1} | loss { epoch_loss/train_sequnce_len :.5f} | accuracy {epoch_mean_acc :.3f} | roc_auc {roc_auc :.3f} ')\n",
    "        \n",
    "        print(test_peformance)\n",
    "        print('\\n')\n",
    "        \n",
    "    test_lost_list.append(test_loss)\n",
    "    train_lost_list.append(epoch_loss/train_sequnce_len)\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86717125-bc32-47f0-a280-1b0696f9feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN_Classifier, self).__init__()\n",
    "        \n",
    "        self.model_embedding=GNN()\n",
    "        self.model_embedding = to_hetero(self.model_embedding, data.metadata(),aggr='max')\n",
    "        self.classifer = Classifer()\n",
    "\n",
    "    def forward(self, x,edges,lookback,question_sequence):\n",
    "        question_sequence_len=question_sequence.shape[1]\n",
    "        node_embeddings = self.model_embedding(x,edges)\n",
    "        \n",
    "        stacked_sample_features=[]\n",
    "        \n",
    "        for question_num in range(lookback,question_sequence_len):\n",
    "            features_concat_list=[]\n",
    "            \n",
    "            for i in range(lookback+1):\n",
    "\n",
    "                lo=question_sequence[0][question_num-i]\n",
    "                atom=question_sequence[1][question_num-i]\n",
    "                prev_answer=torch.tensor([question_sequence[2][question_num-1-i]]).float()\n",
    "                \n",
    "                features_concat_list.extend([node_embeddings['atom'][atom]])\n",
    "                features_concat_list.extend([node_embeddings['lo'][lo]])\n",
    "                features_concat_list.extend([prev_answer])\n",
    "                   \n",
    "            user_embeddings=torch.cat(features_concat_list)\n",
    "            \n",
    "            stacked_sample_features.append(user_embeddings)\n",
    "            \n",
    "        stacked_sample_features= torch.stack( stacked_sample_features  )  \n",
    "        \n",
    "        \n",
    "        rnn_outputs = self.classifer(stacked_sample_features)\n",
    "    \n",
    "        return rnn_outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
